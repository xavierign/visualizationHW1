

## Familiarity with Computational Tools

In this section we explore methods to visualize the relative knowledge of the class as far as computational tools are concerned. In the survey, students were asked to select
which tools they felt comfortable using from among a list of 20. The type of tools varies from specific computer languages like Python, to more general applications like Google Drive.

We present two methods for visualizing which tools the greatest number of students feel comfortable with. The first is a Word Cloud. The Word Cloud below prints words with a font size that is correlated to the frequency of responses. So, for example, if more students selected 'R' than any other tool, then 'R' would show up in the largest font.


```{r,include=FALSE}
options(warn=-1)
rm(list = ls())
library(tm)
library(SnowballC)
library(wordcloud)
library(xlsx)
library(RColorBrewer)
library(stringr)


survey <- read.xlsx('Survey+Response.xlsx',sheetIndex = 1)
tools = as.vector(survey$Experiences.with.tools)

docs <- Corpus(VectorSource(tools))

# Convert the text to lower case
#docs <- tm_map(docs, content_transformer(tolower))

# Remove numbers
#docs <- tm_map(docs, removeNumbers)

# Remove english common stopwords
#docs <- tm_map(docs, removeWords, stopwords("english"))

# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("formerly","docs","terminal","command",
                                    "line","expressions","grep","knitr","web","css",
                                    "js","regular","sweave","google"))

# Remove punctuations
docs <- tm_map(docs, removePunctuation)

# Eliminate extra white spaces
#docs <- tm_map(docs, stripWhitespace)

# Text stemming
# docs <- tm_map(docs, stemDocument)

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
v = c(v,R=91,"C++" = 36,"sweave_knitr"=9,"reg_expressions"=18)
v = sort(v, decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
print(head(d, 30))

set.seed(1234)
```

```{r, echo=FALSE, fig.height = 5, fig.width = 5}
wordcloud(words = d$word, freq = d$freq, min.freq = 0,
          max.words=2000, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

The Word Cloud, while not quantitative, provides a nice visual to give the audience a general sense of which tools are most well known among the class. We see that 'R' and 'Python' show up frequently, as well as 'Excel' and 'Drive'. We were not surprised by this result, since these languages and tools are commonly pushed in our classes.

For a more quantitative visualization of the responses, we also present a histogram which is ordered from largest number of responses to smallest. From this we can see more accurately than with the Word Cloud which tools were responded to more frequently than others. 



```{r, include=FALSE}
findFreqTerms(dtm, lowfreq = 3)
findAssocs(dtm, terms = "freedom", corlimit = 0.3)
```

```{r, echo=FALSE, fig.height = 5, fig.width = 5}
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
        col ="lightblue", main ="Most frequent tools",
        ylab = "Word frequencies")

```


The conclusion one can draw from this visualization of our comfort level with various tools is that the majority of the class has experience with 'R' and 'Python'. Some of the more specialized tools like 'SQL' and 'Github' are less familiar to the class, and certain other tools such as 'Sweave' and 'grep' do not show up at all because few people are experienced with them. These considerations would be important for an instructor wanting to determine what class members know coming in. 

